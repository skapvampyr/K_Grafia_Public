{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66ab3cc5-aee4-415a-9391-1e5d37ccaf1d",
   "metadata": {},
   "source": [
    "# Skill 3: Q&A against a SQL Database (Azure SQL, Azure Fabric, Synapse, SQL Managed Instance, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306fc0a9-4044-441d-9ba7-f54f32e6ea9f",
   "metadata": {},
   "source": [
    "Now that we know (from the prior Notebook) how to query tabular data on a CSV file and how to perform data analysis with Python, let's try now to keep the data at is source and ask questions directly to a SQL Database.\n",
    "The goal of this notebook is to demonstrate how a LLM can understand a human question and translate that into a SQL query to get the answer. \n",
    "\n",
    "We will be using the Azure SQL Server that you created on the initial deployment. However the same code below works with any SQL database like Synapse for example.\n",
    "\n",
    "Let's begin.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fb79a3-4856-4721-988c-112813690a90",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_community.agent_toolkits import create_sql_agent, SQLDatabaseToolkit\n",
    "from langchain_community.utilities.sql_database import SQLDatabase\n",
    "\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "\n",
    "from common.prompts import MSSQL_AGENT_PREFIX\n",
    "\n",
    "from IPython.display import Markdown, HTML, display  \n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"credentials.env\")\n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258a6e99-2d4f-4147-b8ee-c64c85296181",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
    "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8e0b32-a6b5-4b1c-943d-e57b737213fa",
   "metadata": {},
   "source": [
    "# Install MS SQL DB driver in your machine\n",
    "\n",
    "Use `lsb_release -a` to verify OS version details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a353df6-0966-4e43-a914-6a2856eb140a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!lsb_release -a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8112882c",
   "metadata": {},
   "source": [
    "## Using AML Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6b661e",
   "metadata": {},
   "source": [
    "\n",
    "You might need the driver installed in order to talk to the SQL DB, so run the below cell once. Then restart the kernel and continue<br>\n",
    "[Microsoft Learn Reference](https://learn.microsoft.com/en-us/sql/connect/odbc/linux-mac/installing-the-microsoft-odbc-driver-for-sql-server?view=sql-server-ver16&tabs=ubuntu18-install%2Calpine17-install%2Cdebian8-install%2Credhat7-13-install%2Crhel7-offline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fbffc7-e149-4eb3-a4db-9f114b06f205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sudo ./download_odbc_driver.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357bca72",
   "metadata": {},
   "source": [
    "## Using Dev Container\n",
    "\n",
    "You might need the driver installed in order to talk to the SQL DB, so run the below cell once. Then restart the kernel and continue<br>\n",
    "[Microsoft Learn Reference](https://learn.microsoft.com/en-us/sql/connect/odbc/linux-mac/installing-the-microsoft-odbc-driver-for-sql-server?view=sql-server-ver16&tabs=ubuntu18-install%2Cdebian17-install%2Cdebian8-install%2Credhat7-13-install%2Crhel7-offline#17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c04434",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# !chmod +x ./download_odbc_driver_dev_container.sh\n",
    "# !./download_odbc_driver_dev_container.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5d5188",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    # Conexión a la base de datos\n",
    "    connection = pymysql.connect(\n",
    "        host=\"201.175.13.78\",\n",
    "        user=\"root\",\n",
    "        password=\"test1234\",\n",
    "        port=32236,\n",
    "        database=\"KIOgrafIA\"\n",
    "    )\n",
    "   \n",
    "\n",
    "    print(\"Conexión exitosa\")\n",
    "\n",
    "\n",
    "except pymysql.MySQLError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "finally:\n",
    "    if connection:\n",
    "        connection.close()\n",
    "        print(\"Conexión cerrada\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf93dc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "\n",
    "try:\n",
    "    # Conexión al servidor MySQL (sin especificar una base de datos)\n",
    "    connection = pymysql.connect(\n",
    "        host=\"201.175.13.78\",\n",
    "        user=\"root\",\n",
    "        password=\"test1234\",\n",
    "        port=32236\n",
    "    )\n",
    "\n",
    "    print(\"Conexión exitosa al servidor MySQL\")\n",
    "\n",
    "    # Crear un cursor para ejecutar consultas\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    # Crear la nueva base de datos\n",
    "    database_name = \"KIOgrafIA\"\n",
    "    cursor.execute(f\"CREATE DATABASE {database_name}\")\n",
    "\n",
    "    print(f\"Base de datos '{database_name}' creada exitosamente\")\n",
    "\n",
    "except pymysql.MySQLError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "finally:\n",
    "    if connection:\n",
    "        connection.close()\n",
    "        print(\"Conexión cerrada\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711770e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "import os\n",
    "\n",
    "# Asegúrate de que las variables de entorno estén configuradas\n",
    "required_vars = [\"SQL_SERVER_NAME\", \"SQL_SERVER_USERNAME\", \"SQL_SERVER_PASSWORD\", \"SQL_SERVER_DATABASE\"]\n",
    "missing_vars = [var for var in required_vars if var not in os.environ]\n",
    "\n",
    "if missing_vars:\n",
    "    raise EnvironmentError(f\"Faltan las siguientes variables de entorno: {', '.join(missing_vars)}\")\n",
    "\n",
    "# Crear la cadena de conexión\n",
    "connection_string = f\"mysql+pymysql://{os.environ['SQL_SERVER_USERNAME']}:{os.environ['SQL_SERVER_PASSWORD']}@{os.environ['SQL_SERVER_NAME']}/{os.environ['SQL_SERVER_DATABASE']}\"\n",
    "\n",
    "# Crear una conexión con SQLAlchemy\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        print(\"Conexión exitosa\")\n",
    "\n",
    "        # Ejecutar la consulta\n",
    "        result = connection.execute(text(\"SELECT * FROM Seguimiento_alertas_AXO\"))\n",
    "\n",
    "        # Mostrar los resultados\n",
    "        for row in result:\n",
    "            print(row)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "finally:\n",
    "    engine.dispose()\n",
    "    print(\"Conexión cerrada\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e30fa1-877d-4d3b-80b0-e17459c1e4f4",
   "metadata": {},
   "source": [
    "# Load Azure SQL DB with the Covid Tracking CSV Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4352dca-7159-4e41-983d-2c6951cf18db",
   "metadata": {},
   "source": [
    "The Azure SQL Database is currently empty, so we need to fill it up with data. Let's use the same data on the Covid CSV filed we used on the prior Notebook, that way we can compare results and methods. \n",
    "For this, you will need to type below the credentials you used at creation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131cd26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_db_config():\n",
    "    \"\"\"Returns the database configuration.\"\"\"\n",
    "    return {\n",
    "        f\"mysql+pymysql://{os.environ['SQL_SERVER_USERNAME']}:{os.environ['SQL_SERVER_PASSWORD']}@{os.environ['SQL_SERVER_NAME']}/{os.environ['SQL_SERVER_DATABASE']}\"\n",
    "        # 'drivername': 'mssql+pyodbc',\n",
    "        # 'username': os.environ[\"SQL_SERVER_USERNAME\"],# + '@' + os.environ[\"SQL_SERVER_NAME\"],\n",
    "        # 'password': os.environ[\"SQL_SERVER_PASSWORD\"],\n",
    "        # 'host': os.environ[\"SQL_SERVER_NAME\"],\n",
    "        # 'port': 3306,\n",
    "        # 'database': os.environ[\"SQL_SERVER_DATABASE\"]\n",
    "        #'query': {'driver': 'ODBC Driver 18 for SQL Server',\n",
    "                    #'TrustServerCertificate': 'yes',\n",
    "                    #'Encrypt': 'yes'}\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26739d89-e075-4098-ab38-92cccf9f9425",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.engine import URL\n",
    "import os\n",
    "\n",
    "def get_db_config():\n",
    "    \"\"\"Returns the database configuration.\"\"\"\n",
    "    return f\"mysql+pymysql://{os.environ['SQL_SERVER_USERNAME']}:{os.environ['SQL_SERVER_PASSWORD']}@{os.environ['SQL_SERVER_NAME']}/{os.environ['SQL_SERVER_DATABASE']}\"\n",
    "        # 'drivername': 'mssql+pyodbc',\n",
    "        # 'username': os.environ[\"SQL_SERVER_USERNAME\"],# + '@' + os.environ[\"SQL_SERVER_NAME\"],\n",
    "        # 'password': os.environ[\"SQL_SERVER_PASSWORD\"],\n",
    "        # 'host': os.environ[\"SQL_SERVER_NAME\"],\n",
    "        # 'port': 3306,\n",
    "        # 'database': os.environ[\"SQL_SERVER_DATABASE\"]\n",
    "        #'query': {'driver': 'ODBC Driver 18 for SQL Server',\n",
    "                    #'TrustServerCertificate': 'yes',\n",
    "                    #'Encrypt': 'yes'}\n",
    "\n",
    "# Configuration for the database connection\n",
    "db_config = {\n",
    "    'drivername': 'mysql+pymysql',\n",
    "    'username': os.environ[\"SQL_SERVER_USERNAME\"] + '@' + os.environ[\"SQL_SERVER_NAME\"],\n",
    "    #'username': os.environ[\"SQL_SERVER_USERNAME\"],\n",
    "    'password': os.environ[\"SQL_SERVER_PASSWORD\"],\n",
    "    'host': os.environ[\"SQL_SERVER_NAME\"],\n",
    "    'port': 3306,\n",
    "    'database': os.environ[\"SQL_SERVER_DATABASE\"],\n",
    "    'query': {'driver': 'ODBC Driver 17 for SQL Server'},\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "# Crear la cadena de conexión\n",
    "connection_string = f\"mysql+pymysql://{os.environ['SQL_SERVER_USERNAME']}:{os.environ['SQL_SERVER_PASSWORD']}@{os.environ['SQL_SERVER_NAME']}/{os.environ['SQL_SERVER_DATABASE']}\"\n",
    "print(\"----\")\n",
    "print(connection_string)\n",
    "print(\"++++++\")\n",
    "print(get_db_config())\n",
    "print(\"<<<<<<<\")\n",
    "\n",
    "db = SQLDatabase.from_uri(get_db_config())\n",
    "#db = SQLDatabase.from_uri(connection_string)\n",
    "llm = AzureChatOpenAI(deployment_name=os.environ[\"GPT4o_DEPLOYMENT_NAME\"], temperature=0.5, max_tokens=2000)\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "\n",
    "\n",
    "# Crear una conexión con SQLAlchemy\n",
    "#engine = create_engine(connection_string)\n",
    "\n",
    "\n",
    "# Create a URL object for connecting to the database\n",
    "#db_url = URL.create(**db_config)\n",
    "\n",
    "# Connect to the Azure SQL Database using the URL string\n",
    "#engine = create_engine(db_url)\n",
    "\n",
    "# Test the connection using the SQLAlchemy 2.0 execution style\n",
    "# with engine.connect() as conn:\n",
    "#     try:\n",
    "#         # Use the text() construct for safer SQL execution\n",
    "#         result = conn.execute(text(\"SELECT @@VERSION\"))\n",
    "#         print(result)\n",
    "#         version = result.fetchone()\n",
    "#         print(\"Connection successful!\")\n",
    "#         print(version)\n",
    "#     except Exception as e:\n",
    "#         print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5640c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, Table, Column, Integer, String, Float, Date, MetaData, Text\n",
    "\n",
    "# Lee el archivo CSV\n",
    "file_path = './data/SF.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Convertir las fechas al formato correcto\n",
    "df['Fecha de cierre'] = pd.to_datetime(df['Fecha de cierre'], format='%d/%m/%Y')\n",
    "df['Fecha Fin Contrato'] = pd.to_datetime(df['Fecha Fin Contrato'], format='%d/%m/%Y')\n",
    "\n",
    "# Conexión a la base de datos MySQL\n",
    "#engine = create_engine('mysql+mysqlconnector://usuario:contraseña@host/base_de_datos')\n",
    "\n",
    "# Definir la tabla con una clave primaria autoincremental\n",
    "metadata = MetaData()\n",
    "\n",
    "table_name = 'SF'\n",
    "sf_table = Table(\n",
    "    table_name, metadata,\n",
    "    Column('id', Integer, primary_key=True, autoincrement=True),\n",
    "    Column('cliente', String(255)),\n",
    "    Column('Etapa', String(255)),\n",
    "    Column('Tipo de Negocio', String(255)),\n",
    "    Column('Fecha de cierre', Date),\n",
    "    Column('Fecha Fin Contrato', Date),\n",
    "    Column('TCV', Float),\n",
    "    Column('Propietario de oportunidad: Nombre completo', String(255)),\n",
    "    Column('Quote Number', String(255)),\n",
    "    Column('Tiempo de contrato', Integer),\n",
    "    Column('QuoteLine', String(255)),\n",
    "    Column('Nombre del producto', String(255)),\n",
    "    Column('Descripción', Text),\n",
    "    Column('Tipo Cargo (Venta)', String(255)),\n",
    "    Column('MRC', Float),\n",
    "    Column('Fabrica', String(255)),\n",
    "    Column('Sector', String(255)),\n",
    "    Column('No. de proyecto', String(255))\n",
    ")\n",
    "\n",
    "# Crear la tabla en la base de datos\n",
    "metadata.create_all(engine)\n",
    "\n",
    "# Cargar los datos en la tabla\n",
    "df.to_sql(table_name, engine, if_exists='append', index=False)\n",
    "\n",
    "print(\"Datos cargados exitosamente en la tabla MySQL\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fd8ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, Table, Column, Integer, String, Date, MetaData, Text\n",
    "\n",
    "# Lee el archivo CSV\n",
    "file_path_cmdb = './data/QL.csv'\n",
    "df_cmdb = pd.read_csv(file_path_cmdb)\n",
    "\n",
    "# Convertir las fechas al formato correcto\n",
    "df_cmdb['Vigencia Licencia'] = pd.to_datetime(df_cmdb['Vigencia Licencia'], format='%d/%m/%Y', errors='coerce')\n",
    "df_cmdb['End of Support Date'] = pd.to_datetime(df_cmdb['End of Support Date'], format='%d/%m/%Y', errors='coerce')\n",
    "\n",
    "# Conexión a la base de datos MySQL\n",
    "#engine = create_engine('mysql+mysqlconnector://usuario:contraseña@host/base_de_datos')\n",
    "\n",
    "# Definir la tabla con una clave primaria autoincremental\n",
    "metadata = MetaData()\n",
    "\n",
    "table_name_cmdb = 'CMDB'\n",
    "cmdb_table = Table(\n",
    "    table_name_cmdb, metadata,\n",
    "    Column('id', Integer, primary_key=True, autoincrement=True),\n",
    "    Column('cliente', String(255)),\n",
    "    Column('OP', String(255)),\n",
    "    Column('Escuadrón', String(255)),\n",
    "    Column('Tecnología', String(255)),\n",
    "    Column('Solución', String(255)),\n",
    "    Column('Marca', String(255)),\n",
    "    Column('Modelo', String(255)),\n",
    "    Column('SO', String(255)),\n",
    "    Column('Número de serie', String(255)),\n",
    "    Column('MAC', String(255)),\n",
    "    Column('Hostname', String(255)),\n",
    "    Column('IP ADMIN', String(255)),\n",
    "    Column('IP SOC', String(255)),\n",
    "    Column('IP HA', String(255)),\n",
    "    Column('Data Center', String(255)),\n",
    "    Column('Rack', String(255)),\n",
    "    Column('Unidad', String(255)),\n",
    "    Column('Soporte', String(255)),\n",
    "    Column('Vigencia Licencia', Date),\n",
    "    Column('Administración', String(255)),\n",
    "    Column('Mesa de servicio', String(255)),\n",
    "    Column('Comentarios', Text),\n",
    "    Column('End of Support Date', Date)\n",
    ")\n",
    "\n",
    "# Crear la tabla en la base de datos\n",
    "metadata.create_all(engine)\n",
    "\n",
    "# Cargar los datos en la tabla\n",
    "df_cmdb.to_sql(table_name_cmdb, engine, if_exists='append', index=False)\n",
    "\n",
    "print(\"Datos cargados exitosamente en la tabla MySQL\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a32ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, Table, Column, Integer, String, Date, MetaData, Text, DateTime\n",
    "\n",
    "# Lee el archivo CSV\n",
    "file_path_cmdb = './data/TCK.csv'\n",
    "df_tck = pd.read_csv(file_path_cmdb)\n",
    "\n",
    "# Conexión a la base de datos MySQL\n",
    "#engine = create_engine('mysql+mysqlconnector://usuario:contraseña@host/base_de_datos')\n",
    "\n",
    "# Definir la tabla con una clave primaria autoincremental\n",
    "metadata = MetaData()\n",
    "#ID de la solicitud\tAsunto\tTécnico\tGrupo de soporte asignado\tProducto\tCategoría 3\tFecha de creación de ticket\tFecha de cerrado de ticket\tEstado de solicitud\tCreado por\tIncidente de seguridad\tImpacto\tUrgencia\tPrioridad\tEstado vencido\tCódigo de cierre de solicitud\tAuxiliar\tTiempo de resolución en horas\tTipo de Incidencia\tTipo de ticket\n",
    "\n",
    "table_name_tck = 'TCK'\n",
    "tck_table = Table(\n",
    "    table_name_tck, metadata,\n",
    "    Column('id', Integer, primary_key=True, autoincrement=True),\n",
    "    Column('cliente', String(255)),\n",
    "    Column('ID de la solicitud', Integer),\n",
    "    Column('Asunto', Text),\n",
    "    Column('Técnico', String(255)),\n",
    "    Column('Grupo de soporte asignado', String(255)),\n",
    "    Column('Producto', String(255)),\n",
    "    Column('Categoría 3', String(255)),\n",
    "    Column('Fecha de creación de ticket', DateTime),\n",
    "    Column('Fecha de cerrado de ticket', DateTime),\n",
    "    Column('Estado de solicitud', String(255)),\n",
    "    Column('Creador', String(255)),\n",
    "    \n",
    "    Column('Incidente de seguridad', String(255)),\n",
    "    Column('Impacto', String(255)),\n",
    "    Column('Urgencia', String(255)),\n",
    "    Column('Prioridad', String(255)),\n",
    "    Column('Estado vencido', String(255)),\n",
    "    Column('Código de cierre de solicitud', String(255)),\n",
    "    Column('Auxiliar', String(255)),\n",
    "    Column('Tiempo de resolución en horas', Float),\n",
    "    Column('Tipo de Incidencia', String(255)),\n",
    "    Column('Tipo de ticket', String(255))\n",
    "\n",
    ")\n",
    "\n",
    "# Crear la tabla en la base de datos\n",
    "metadata.create_all(engine)\n",
    "\n",
    "# Convertir las fechas al formato correcto\n",
    "df_tck['Fecha de creación de ticket'] = pd.to_datetime(df_tck['Fecha de creación de ticket'], format='%d/%m/%Y %I:%M %p', errors='coerce')\n",
    "df_tck['Fecha de cerrado de ticket'] = pd.to_datetime(df_tck['Fecha de cerrado de ticket'], format='%d/%m/%Y %I:%M %p', errors='coerce')\n",
    "\n",
    "# Cargar los datos en la tabla\n",
    "df_tck.to_sql(table_name_tck, engine, if_exists='append', index=False)\n",
    "\n",
    "print(\"Datos cargados exitosamente en la tabla MySQL\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acaf202c-33a1-4105-b506-c26f2080c1d8",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numero_oportunidad\n",
      "tipo_negocio_oportunidad\n",
      "etapa_de_la_oportunidad\n",
      "plazo_contratacion_oportunidad\n",
      "fecha_de_cierre_oportunidad\n",
      "fecha_vencimiento_oportunidad\n",
      "fecha_fin_mrc_oportunidad\n",
      "numero_proyecto_oportunidad\n",
      "numero_quote_principal_oportunidad\n",
      "nombre_cliente_final\n",
      "industria_cuenta\n",
      "monto_nrc_kcs_quote\n",
      "monto_mrc_convertido_kcs_quote\n",
      "monto_tcv_convertido_kcs_quote\n",
      "nombre_quote_line\n",
      "descripcion_quote_line\n",
      "capa_tecnologica_prod_quote_line\n",
      "subcapa_tecnologica_prod_quote_line\n",
      "monto_nrc_quote_line\n",
      "name 'engine' is not defined\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "\n",
    "# Conexión a la base de datos\n",
    "connection = pymysql.connect(\n",
    "    host=\"201.175.13.78\",\n",
    "    user=\"root\",\n",
    "    password=\"test1234\",\n",
    "    port=32236,\n",
    "    database=\"KIOgrafIA\"\n",
    ")\n",
    "\n",
    "# Read CSV file into a pandas dataframe\n",
    "csv_path = \"./data/QL.csv\"\n",
    "df = pd.read_csv(csv_path).fillna(value = 0)\n",
    "\n",
    "# Infer column names and data types\n",
    "column_names = df.columns.tolist()\n",
    "column_types = df.dtypes.to_dict()\n",
    "\n",
    "\n",
    "# Generate SQL statement to create table\n",
    "table_name = 'CMDB'\n",
    "\n",
    "create_table_sql = f\"CREATE TABLE {table_name} (\"\n",
    "for name, dtype in column_types.items():\n",
    "    print(name)\n",
    "    if dtype == 'object':\n",
    "        create_table_sql += f\"{name} VARCHAR(255), \"\n",
    "    elif dtype == 'int64':\n",
    "        create_table_sql += f\"{name} INT, \"\n",
    "    elif dtype == 'float64':\n",
    "        create_table_sql += f\"{name} FLOAT, \"\n",
    "    elif dtype == 'bool':\n",
    "        create_table_sql += f\"{name} TINYINT(1), \"\n",
    "    elif dtype == 'datetime64[ns]':\n",
    "        create_table_sql += f\"{name} DATETIME, \"\n",
    "create_table_sql = create_table_sql[:-2] + \")\"\n",
    "\n",
    "try:\n",
    "    #Createse the table in Azure SQL\n",
    "    with engine.connect() as conn:\n",
    "        # Execute the create table SQL statement\n",
    "        conn.execute(text(create_table_sql))\n",
    "        print(\"Table\", table_name, \"successfully created\")\n",
    "    # Insert data into SQL Database\n",
    "    lower = 0\n",
    "    upper = 1000\n",
    "    limit = df.shape[0]\n",
    "\n",
    "    while lower < limit:\n",
    "        df[lower:upper].to_sql(table_name, con=engine, if_exists='append', index=False)\n",
    "        print(\"rows:\", lower, \"-\", upper, \"inserted\")\n",
    "        lower = upper\n",
    "        upper = min(upper + 1000, limit)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ad46af-11a4-41a6-94af-15509fd9e16c",
   "metadata": {},
   "source": [
    "# Query with LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2ef524-565a-4f28-9955-fce0d01bbe21",
   "metadata": {},
   "source": [
    "**Note**: We are here using Azure SQL, however the same code will work with Synapse, SQL Managed instance, or any other SQL engine. You just need to provide the right values for the ENV variables and it will connect succesfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faef3c0-8166-4f3b-a5e3-d30acfd65fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(deployment_name=os.environ[\"GPT4o_DEPLOYMENT_NAME\"], temperature=0.5, max_tokens=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbe650c-9e0a-4209-9595-de13f2f1ee0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create the db object\n",
    "#db_url = \"mysql+pymysql://username:password@host/database\"\n",
    "db = SQLDatabase.from_uri(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae80c022-415e-40d1-b205-1744a3164d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Natural Language question (query)\n",
    "QUESTION = \"\"\"\n",
    "Del cliente Abilia dime cual es su TCV total, cuantos tickets tiene, y cuantas tecnologias se administran?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95052aba-d0c5-4883-a0b6-70c20e236b6a",
   "metadata": {},
   "source": [
    "### SQL Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8b1352-d6d7-4319-a0b8-ae7b9c2fd234",
   "metadata": {},
   "source": [
    "LangChain has a SQL Agent which provides a more flexible way of interacting with SQL Databases than a chain. The main advantages of using the SQL Agent are:\n",
    "\n",
    "    It can answer questions based on the databases’ schema as well as on the databases’ content (like describing a specific table).\n",
    "    It can recover from errors by running a generated query, catching the traceback and regenerating it correctly.\n",
    "    It can query the database as many times as needed to answer the user question.\n",
    "    It will save tokens by only retrieving the schema from relevant tables.\n",
    "\n",
    "To initialize the agent we’ll use the `create_sql_agent` constructor. This agent uses the SQLDatabaseToolkit which contains tools to:\n",
    "\n",
    "    Create and execute queries\n",
    "    Check query syntax\n",
    "    Retrieve table descriptions\n",
    "    … and more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b51fb36-68b5-4770-b5f1-c042a08e0a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "\n",
    "agent_executor = create_sql_agent(\n",
    "    prefix=MSSQL_AGENT_PREFIX,\n",
    "    llm=llm,\n",
    "    toolkit=toolkit,\n",
    "    top_k=30,\n",
    "    agent_type=\"openai-tools\",\n",
    "    verbose=True,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c6c6f5-4a14-403f-a1d0-fe6b0c34a563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we know by now, Agents use expert/tools. Let's see which are the tools for this SQL Agent\n",
    "agent_executor.tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7bb8cf-8661-4174-8185-c64b4b20670d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = agent_executor.invoke(QUESTION) \n",
    "except Exception as e:\n",
    "    response = str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23d2135-2199-474e-ae83-455aefc9b93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "printmd(response[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfef208f-321c-490e-a50e-e92602daf125",
   "metadata": {},
   "source": [
    "**IMPORTANT NOTE**: If you don't specify the column name on the question, runing the above cell multiple times will yield diferent results some times. <br>\n",
    "The reason is:\n",
    "The column names are ambiguous, hence it is hard even for Humans to discern what are the right columns to use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cbc405-26e2-471e-9626-2a0df07f5ddc",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7381ea5f-7269-4e1f-8b0c-1e2c04bd84c0",
   "metadata": {},
   "source": [
    "In this notebook, we achieved our goal of Asking a Question in natural language to a dataset located on a SQL Database.  We did this by using purely prompt engineering (Langchain does it for us) and the cognitive power of GPT models.\n",
    "\n",
    "This process shows why it is NOT necessary to move the data from its original source as long as the source has an API and a common language we can use to interface with. LLMs have been trained on the whole public Github corpus, so it can pretty much understand most of the coding and database query languages that exists out there. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02073623-91b4-40d6-8eaf-cb6d9c6a7a9a",
   "metadata": {},
   "source": [
    "# NEXT\n",
    "\n",
    "The Next Notebook will show you how to create a custom agent that connects to the internet using BING SEARCH API to answer questions grounded on search results with citations. Basically a clone of Bing Chat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c169d9-ae2e-4188-b500-869d14b2579c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
