{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poner todo junto\n",
    "\n",
    "Hasta ahora hemos hecho lo siguiente en los cuadernos anteriores:\n",
    "\n",
    "- **Cuadernos 01**: Cargamos el Azure Search Engine con PDFs enriquecidos en index: «cogsrch-index-files»\n",
    "- **Cuaderno 02**: Añadimos modelos GPT de AzureOpenAI para mejorar la producción de la respuesta mediante el uso de Utility Chains de LLMs.\n",
    "- **Cuaderno 03**: Añadimos memoria a nuestro sistema para alimentar un Chat Bot conversacional\n",
    "- **Cuaderno 04**: Introducimos Agentes y Herramientas y construimos la primera Habilidad/Agente, que puede hacer RAG sobre un motor de búsqueda\n",
    "\n",
    "Nos falta una cosa más: **¿Cómo unimos todas estas características en un inteligente GPT Smart Search Engine Chat Bot?\n",
    "\n",
    "Queremos un asistente virtual para nuestra empresa que pueda recibir la pregunta, pensar qué herramienta utilizar y, a continuación, obtener la respuesta. El objetivo es que, independientemente de la fuente de la información, el Asistente pueda responder a la pregunta correctamente utilizando la herramienta adecuada.\n",
    "\n",
    "En este Cuaderno vamos a crear ese Agente «inteligente» (también llamado Agente Maestro), que\n",
    "\n",
    "1) entiende la pregunta, interactúa con el usuario \n",
    "2) habla con otros Agentes especializados\n",
    "3) una vez que obtiene la respuesta, la entrega al usuario o deja que el Agente especializado la entregue directamente.\n",
    "\n",
    "Este es el mismo concepto de [AutoGen](https://www.microsoft.com/en-us/research/blog/autogen-enabling-next-generation-large-language-model-applications/): Agentes que hablan entre sí.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://www.microsoft.com/en-us/research/uploads/prod/2023/09/AutoGen_Fig1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "import requests\n",
    "from operator import itemgetter\n",
    "from typing import Union, List\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.agents import AgentExecutor, Tool, create_openai_tools_agent\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory, CosmosDBChatMessageHistory\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.runnables import ConfigurableFieldSpec, ConfigurableField\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.output_parsers import JsonOutputToolsParser\n",
    "from langchain_core.runnables import (\n",
    "    Runnable,\n",
    "    RunnableLambda,\n",
    "    RunnableMap,\n",
    "    RunnablePassthrough,\n",
    ")\n",
    "\n",
    "#custom libraries that we will use later in the app\n",
    "from common.utils import (\n",
    "    DocSearchAgent, \n",
    "    reduce_openapi_spec\n",
    ")\n",
    "from common.callbacks import StdOutCallbackHandler\n",
    "from common.prompts import CUSTOM_CHATBOT_PROMPT \n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"credentials.env\")\n",
    "\n",
    "from IPython.display import Markdown, HTML, display \n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtener las Herramientas - Agente DocSearch\n",
    "\n",
    "**Considere el siguiente concepto:** Los agentes, que son esencialmente entidades de software diseñadas para realizar tareas específicas, pueden estar equipados con herramientas. Estas herramientas a su vez pueden ser otros agentes, cada uno poseyendo su propio conjunto de herramientas. Esto crea una estructura en capas en la que las herramientas pueden ir desde secuencias de código hasta acciones humanas, formando cadenas interconectadas. En última instancia, estás construyendo una red de agentes y sus respectivas herramientas, todos trabajando en colaboración para resolver una tarea específica (esto es lo que es ChatGPT). Esta red funciona aprovechando las capacidades únicas de cada agente y herramienta, creando un sistema dinámico y eficiente para la resolución de tareas.\n",
    "\n",
    "En el fichero `common/utils.py` creamos Clases de Herramientas de Agente para cada una de las Funcionalidades que desarrollamos en Cuadernos anteriores. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_handler = StdOutCallbackHandler()\n",
    "cb_manager = CallbackManager(handlers=[cb_handler])\n",
    "\n",
    "COMPLETION_TOKENS = 2000\n",
    "\n",
    "# We can run the everything with GPT3.5, but try also GPT4 and see the difference in the quality of responses\n",
    "# You will notice that GPT3.5 is not as reliable when using multiple sources.\n",
    "\n",
    "llm = AzureChatOpenAI(deployment_name=os.environ[\"GPT35_DEPLOYMENT_NAME\"], \n",
    "                      temperature=0, max_tokens=COMPLETION_TOKENS)\n",
    "\n",
    "# Uncomment below if you want to see the answers streaming\n",
    "# llm = AzureChatOpenAI(deployment_name=os.environ[\"GPT35_DEPLOYMENT_NAME\"], temperature=0, max_tokens=COMPLETION_TOKENS, streaming=True, callback_manager=cb_manager)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_indexes = [\"cogsrch-index-files\"]\n",
    "doc_search = DocSearchAgent(llm=llm, indexes=doc_indexes,\n",
    "                           k=6, reranker_th=1,\n",
    "                           sas_token=os.environ['BLOB_SAS_TOKEN'],\n",
    "                           name=\"docsearch\",\n",
    "                           description=\"useful when the questions includes the term: docsearch\",\n",
    "                           callback_manager=cb_manager, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables/perillas a utilizar para la personalización\n",
    "\n",
    "Como has visto hasta ahora, hay muchas perillas que puedes marcar hacia arriba o hacia abajo con el fin de cambiar el comportamiento de tu aplicación GPT Smart Search engine, estas son las variables que puedes afinar:\n",
    "\n",
    "- <u>llm</u>:\n",
    "  - **deplyment_name**: este es el nombre de despliegue de su modelo Azure OpenAI. Esto, por supuesto, dicta el nivel de razonamiento y la cantidad de tokens disponibles para la conversación. Para un sistema de producción necesitará gpt-4-32k. Este es el modelo que te dará suficiente poder de razonamiento para trabajar con agentes, y suficientes tokens para trabajar con respuestas detalladas y memoria de conversación.\n",
    "  - **temperature**: Cómo de creativas quieres que sean tus respuestas\n",
    "  - **max_tokens**: Cómo de largas quieres que sean tus respuestas. Se recomienda un mínimo de 500\n",
    "- <u>Herramientas</u>: A cada herramienta puedes agregar los siguientes parámetros para modificar los predeterminados (establecidos en utils.py), estos son muy importantes ya que forman parte del prompt del sistema y determina que herramienta usar y cuando.\n",
    "  - **name**: el nombre de la herramienta\n",
    "  - **description**: cuando el agente cerebral debe usar esta herramienta\n",
    "- <u>DocSearchAgent</u>: \n",
    "  - **k**: Los k mejores resultados por índice de la acción de búsqueda de texto\n",
    "  - **similarity_k**: los k mejores resultados combinados de la acción de búsqueda vectorial\n",
    "  - **reranker_th**: umbral del reranker de búsqueda semántica. Selecciona los resultados que están por encima del umbral. Puntuación máxima posible=4\n",
    "\n",
    "  \n",
    "en `utils.py` también se puede afinar:\n",
    "- <u>model_tokens_limit</u>: En esta función puedes editar cual es el máximo permitido de tokens reservados para el contenido. Recuerda que los restantes serán para el prompt del sistema más la respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruebe las herramientas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Documents Search Tool with a question we know it doesn't have the knowledge for\n",
    "printmd(doc_search.run(\"what is the weather today in Dallas?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Document Search Tool with a question that we know it has the answer for\n",
    "printmd(await doc_search.arun(\"What are some examples of reinforcement learning?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir qué herramientas le vamos a dar a nuestro agente cerebral\n",
    "\n",
    "Vaya a `common/utils.py` para verificar la definición de herramientas y las instrucciones sobre qué herramienta usar y cuándo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [doc_search ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opción 1: usar funciones OpenAI como enrutador\n",
    "\n",
    "Necesitamos un método para dirigir la pregunta a la herramienta correcta; una forma sencilla de hacerlo es utilizar las funciones de los modelos OpenAI a través de la API de herramientas (modelos 1106 y posteriores). Para hacer esto, necesitamos vincular estas herramientas/funciones al modelo y dejar que el modelo responda con la herramienta adecuada para usar.\n",
    "\n",
    "La ventaja de esta opción es que no hay ningún otro agente en el medio entre los expertos (herramientas de agentes) y el usuario. Cada herramienta de agente responde directamente. Además, otra ventaja es que se pueden llamar varias herramientas en paralelo.\n",
    "\n",
    "**Nota**: en este método es importante que cada herramienta de agente tenga el mismo mensaje de perfil del sistema para que cumplan con las mismas pautas de respuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools)\n",
    "tool_map = {tool.name: tool for tool in tools}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_tool(tool_invocation: dict) -> Union[str, Runnable]:\n",
    "    \"\"\"Function for dynamically constructing the end of the chain based on the model-selected tool.\"\"\"\n",
    "    tool = tool_map[tool_invocation[\"type\"]]\n",
    "    return RunnablePassthrough.assign(output=itemgetter(\"args\") | tool)\n",
    "\n",
    "def print_response(result: List):\n",
    "    for answer in result:\n",
    "        printmd(\"**\"+answer[\"type\"] + \"**\" + \": \" + answer[\"output\"])\n",
    "        printmd(\"----\")\n",
    "    \n",
    "# .map() allows us to apply a function to a list of inputs.\n",
    "call_tool_list = RunnableLambda(call_tool).map()\n",
    "agent = llm_with_tools | JsonOutputToolsParser() | call_tool_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent.invoke(\"hi, how are you, what is your name?\")\n",
    "print_response(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opción 2: utilizar un agente orientado al usuario que llame a los expertos en herramientas del agente\n",
    "\n",
    "Con este método, creamos un agente de cara al usuario que habla con el usuario y también habla con los expertos (herramientas del agente)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicializar el agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_openai_tools_agent(llm, tools, CUSTOM_CHATBOT_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_history(session_id: str, user_id: str) -> CosmosDBChatMessageHistory:\n",
    "    cosmos = CosmosDBChatMessageHistory(\n",
    "        cosmos_endpoint=os.environ['AZURE_COSMOSDB_ENDPOINT'],\n",
    "        cosmos_database=os.environ['AZURE_COSMOSDB_NAME'],\n",
    "        cosmos_container=os.environ['AZURE_COSMOSDB_CONTAINER_NAME'],\n",
    "        connection_string=os.environ['AZURE_COMOSDB_CONNECTION_STRING'],\n",
    "        session_id=session_id,\n",
    "        user_id=user_id\n",
    "        )\n",
    "\n",
    "    # prepare the cosmosdb instance\n",
    "    cosmos.prepare_cosmos()\n",
    "    return cosmos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_agent_executor = RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"question\",\n",
    "    history_messages_key=\"history\",\n",
    "    history_factory_config=[\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"user_id\",\n",
    "            annotation=str,\n",
    "            name=\"User ID\",\n",
    "            description=\"Unique identifier for the user.\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        ),\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"session_id\",\n",
    "            annotation=str,\n",
    "            name=\"Session ID\",\n",
    "            description=\"Unique identifier for the conversation.\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is where we configure the session id and user id\n",
    "random_session_id = \"session\"+ str(random.randint(1, 1000))\n",
    "ramdom_user_id = \"user\"+ str(random.randint(1, 1000))\n",
    "\n",
    "config={\"configurable\": {\"session_id\": random_session_id, \"user_id\": ramdom_user_id}}\n",
    "print(random_session_id, ramdom_user_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hablemos ahora con nuestro chatbot de GPT Smart Search Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This question should not use any tool, the brain agent should answer it without the use of any tool\n",
    "printmd(brain_agent_executor.invoke({\"question\": \"Hi, I'm Pablo Marin, how are you doing today?\"}, config=config)[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printmd(brain_agent_executor.invoke({\"question\": \"docsearch, what is a NP-complete problem?\"}, config=config)[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printmd(brain_agent_executor.invoke({\"question\": \"can you tell an example?\"}, config=config)[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resumen\n",
    "\n",
    "¡Genial! ¡Acabamos de crear el motor de búsqueda inteligente GPT!\n",
    "En este Cuaderno creamos el cerebro, el Agente de toma de decisiones que decide qué Herramienta utilizar para responder la pregunta del usuario. Esto es lo que era necesario para tener un chatbot inteligente.\n",
    "\n",
    "Podemos tener muchas herramientas para realizar diferentes tareas, incluida la conexión a API, el manejo de sistemas de archivos e incluso el uso de humanos como herramientas. Para obtener más referencia, consulte [AQUÍ](https://python.langchain.com/docs/integrations/tools/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
